### Scarpy
Scarpy是目前最为流行的爬虫框架之一，它具有速度快，简介，可扩展性强的特点。

#### 工作流程
1. 爬虫中其实的url构造成request对象，并传给调度器
2. 引擎从调度器中获取request对象，然后交给下载器
3. 由下载器获取页面源代码，并封装成response对象，反馈给引擎
4. 引擎获取到的response对象传递给spider（爬虫）,由spider对数据进行解析，并反馈给引擎
5. 引擎将数据传给管道，进行数据持久化或再次进行数据处理
6. 在此期间，如果spider获取的不是数据而是子页面，可以进一步交给调度器，重复步骤2

* 引擎（engine）：scrapy的核心，所有模块的衔接，数据流程处理
* 调度器（scheduler）:本质上这东西可以看成一个队列，里面存放着一堆我们即将要发送的请求，可以看成是一个url容器。他决定了下一步要爬取哪一个url，通常我们在这里对url进行去重操作
* 下载器（downloader）：它的本质是用来发动请求的一个模块，小白们完全可以把它理解成一个get_page_source()的功能。只不过这货返回的是一个response对象。
* 爬虫（spider）：这是我们第一部分的内容，负责解析下载器返回的response对象，从中我们可以提取到我们需要的数据。
* 管道（pipeline）：这是我们要写的第二部分的内容，主要负责数据的存储和各种持久化操作。

由上可以看出Scarpy把我们的爬虫分成多个模块，并且多个模块之间互不打扰

#### 实战
1. 新建一个文件夹，右键，打开于终端
2. 输入 scrapy startproject '随便起的文件名1'
3. 在spiders文件，右键，打开于终端
4. 输入 scrapy genspider '随便起的文件名2' '爬取的域名'
5. 接着输入  '随便起的名字2'
6. 在settings中输入 LOG_LEVEL = "WARNING" 把日志去掉，看着省心
7. 接着在终端输入 scrapy crawl '随便起的文件名2'








